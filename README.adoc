= Stackable Operator for Apache Spark

This is a Kubernetes Operator to manage Apache Spark clusters.

It is written by https://www.stackable.de[Stackable] in Rust, and it is supposed to be used with the https://github.com/stackabletech/agent[Stackable Agent] instead of the Kubernetes kubelet.

== Building

This operator is written in Rust.
It is developed against the latest Rust release (1.50.0-nightly at the time of writing this).

NOTE: This requires Rust nightly due to the use of the `backtrace` feature.

    cargo build

== Configuration Options

The cluster can be configured via a YAML file.
Each node type (Master, Worker, History-Server) can have multiple instances within multiple selectors.
Multiple instances in the same selector can lead to port duplicates which results in the affected node
to increase the port one by one (if max_port_retries is not set to 0). Keep that in mind when e.g. running multiple masters without specified ports
on the same node.

    apiVersion: spark.stackable.tech/v1
    kind: SparkCluster
    metadata:
    name: spark-cluster
    spec:
      version: "3.0.1"
      masters:
      selectors:
        default:
          selector:
            matchLabels:
              kubernetes.io/hostname: master-node
          instances: 1
          instancesPerNode: 1
          config:
            masterPort: 7078
            masterWebUiPort: 8081
      workers:
        selectors:
          1core1g:
            selector:
              matchLabels:
                kubernetes.io/hostname: worker-1-node
            instances: 1
            instancesPerNode: 1
            config:
              cores: 1
              memory: "1g"
              workerPort: 3031
              workerWebUiPort: 8083
          2core2g:
            selector:
              matchLabels:
                kubernetes.io/hostname: worker-2-node
            instances: 1
            instancesPerNode: 1
            config:
              cores: 2
              memory: "2g"
              workerPort: 3032
              workerWebUiPort: 8084
      historyServers:
        selectors:
          default:
            selector:
              matchLabels:
                kubernetes.io/hostname: history-server-node
            instances: 1
            instancesPerNode: 1
            config:
              historyWebUiPort: 18081



=== Structure

There are three levels of configuration:

[cols="1,1"]
|===
|Common shared options
|Contains configuration that is shared within the whole cluster. E.g. the spark image, secrets, encryption or logging options.

|Node type options
|This configuration is shared for all nodes of a certain type (Master, Worker, History-Server)

|Selector specific options
|Options provided in the selector are limited to one specific node of a node type (Master, Worker, History-Server) and apply to one physical machine.
|===

=== Common shared options
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties

|version
|string
|The spark version used in the format: x.y.z
|

|logDir
|string
|The log folder for spark applications (must created by user)
|spark.history.fs.logDirectory=logDir, spark.eventLog.enabled=true, spark.eventLog.dir=logDir;

|secret
|string
|A secret shared between nodes and required to submit applications via spark-submit
|spark.authenticate=true, spark.authenticate.secret=secret;

|maxPortRetries
|integer
|Maximum number of retries when binding to a port before giving up. When a port is given a specific value (non 0), each subsequent retry will increment the port used in the previous attempt by 1 before retrying. This essentially allows it to try a range of ports from the start port specified to port + maxRetries.
|spark.port.maxRetries
|===

=== Node type options
T.b.d.

=== Selector specific options
==== Master
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties

|masterPort
|integer
|Start the master on a different port (default: 7077).
|SPARK_MASTER_PORT

|masterWebUiPort
|integer
|Port for the master web UI (default: 8080).
|SPARK_MASTER_WEBUI_PORT
|===
==== Worker
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties

|workerPort
|integer
|Start the Spark worker on a specific port (default: random).
|SPARK_WORKER_PORT

|workerWebUiPort
|integer
|Port for the worker web UI (default: 8081).
|SPARK_WORKER_WEBUI_PORT

|cores
|integer
|Total number of cores to allow Spark jobs to use on the machine (default: all available cores).
|SPARK_WORKER_CORES

|memory
|string
|Total amount of memory to allow Spark jobs to use on the machine, e.g. 1000M, 2G (default: total memory minus 1 GB).
|SPARK_WORKER_MEMORY
|===

==== History Server
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties

|storePath
|string
|A local directory where to cache application history data. If set, the history server will store application data on disk instead of keeping it in memory. The data written to disk will be re-used in the event of a history server restart.
|spark.history.store.path

|historyUiPort
|integer
|The port to which the web interface of the history server binds (default: 18080).
|spark.history.ui.port
|===

The docs can be found in the `docs` subdirectory, and they are published together with docs for all other Stackable products at https://docs.stackable.tech.

