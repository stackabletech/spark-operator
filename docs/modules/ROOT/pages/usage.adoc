= Usage

== Create an Apache Spark cluster

If you followed the installation instructions, you should now have a Stackable Operator for Apache Spark up and running and you are ready to create your first Apache Spark cluster.

The example below creates an Apache Spark 3.0.1 cluster with one master (because of `replicas: 1`), one history server and as many workers as nodes available.
Because of `enableMonitoring: true`, all pods will be annotated for metric scraping. Metrics are retrieved from Spark's built in Prometheus Servlet.

    cat <<EOF | kubectl apply -f -
    apiVersion: spark.stackable.tech/v1alpha1
    kind: SparkCluster
    metadata:
      name: simple-spark
    spec:
      version: "3.0.1"
      config:
        enableMonitoring: true
      masters:
        roleGroups:
          default:
            selector:
              matchLabels:
                kubernetes.io/os: linux
            replicas: 1
            config: {}
      workers:
        roleGroups:
          2core2g:
            selector:
              matchLabels:
                kubernetes.io/os: linux
            config:
              cores: 2
              memory: "2g"
      historyServers:
        roleGroups:
          default:
            selector:
              matchLabels:
                kubernetes.io/os: linux
            replicas: 1
            config: {}
    EOF

== Using the Apache Spark cluster

The example above sets up a https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport[NodePort] service named `simple-spark-master` that clients can use to run Spark jobs.

This is how the list of services might look like:

    kubectl get svc
    NAME                                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                         AGE
    kubernetes                            ClusterIP   10.96.0.1      <none>        443/TCP                         5h38m
    simple-spark-history-server-default   ClusterIP   None           <none>        18080/TCP                       2m54s
    simple-spark-master                   NodePort    10.96.63.134   <none>        8080:31296/TCP,7077:32274/TCP   2m54s
    simple-spark-master-default           ClusterIP   None           <none>        8080/TCP,7077/TCP               2m54s
    simple-spark-slave-2core2g            ClusterIP   None           <none>        8081/TCP                        2m54s

To start a Spark shell from inside the cluster you would run:

    /stackable/spark/bin/spark-shell --master spark://simple-spark-master-default:7077

and from outside: 

    spark-shell --master spark://<node-ip>>:32274

where `<node-ip>` is the IP address of the node running your master.

== Configuration properties

There are three levels of configuration:

[cols="1,1"]
|===
|Common properties
|Contains configuration that is shared within the whole cluster. For example the spark version, secrets, encryption or logging options.

|Role properties
|This configuration is shared for all nodes of a certain type (Master, Worker, History-Server)

|Role Group properties
|Options provided in the role group are limited to one specific role and role group.
|===

=== Common properties
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties

|version
|string
|The spark version used in the format: x.y.z
|

|secret
|string
|A secret shared between nodes and required to submit applications via spark-submit
|spark.authenticate=true, spark.authenticate.secret=secret;

|maxPortRetries
|integer
|Maximum number of retries when binding to a port before giving up. When a port is given a specific value (non 0), each subsequent retry will increment the port used in the previous attempt by 1 before retrying. This essentially allows it to try a range of ports from the start port specified to port + maxRetries.
|spark.port.maxRetries
|===

=== Role properties
T.b.d.

=== Role Group properties
==== Master
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties
|===

==== Worker
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties

|cores
|integer
|Total number of cores to allow Spark jobs to use on the machine (default: all available cores).
|SPARK_WORKER_CORES

|memory
|string
|Total amount of memory to allow Spark jobs to use on the machine, e.g. 1000M, 2G (default: total memory minus 1 GB).
|SPARK_WORKER_MEMORY
|===

==== History Server
[cols="1,1,1,1"]
|===
|Name
|Type
|Description
|Related Spark properties

|storePath
|string
|A local directory where to cache application data. If set, the history server will store application data on disk instead of keeping it in memory. The data written to disk will be re-used in the event of a history server restart.
|spark.history.store.path
|===
